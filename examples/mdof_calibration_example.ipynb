{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14468b6a",
   "metadata": {},
   "source": [
    "# 0. Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c5109",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the vulnerability toolkit library\n",
    "import sys\n",
    "repoDir = 'C:/Users/Moayad/Documents/GitHub/stickModel'\n",
    "sys.path.insert(1, f'{repoDir}')\n",
    "from stickModel import stickModel\n",
    "from utils import *\n",
    "from units import *\n",
    "from postprocessors import *\n",
    "from plotters import *\n",
    "from im_calculator import *\n",
    "\n",
    "### Import other libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from math import sqrt, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f6ea7",
   "metadata": {},
   "source": [
    "# 1. User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Capacity Curves Directory\n",
    "capCurvesDir= f'{repoDir}/raw/ip-capacities'\n",
    "\n",
    "### Define Building Class\n",
    "currentBuildingClass='CR_LFINF+CDM+DUM_H4'\n",
    "\n",
    "### Define Ground-Motion Records Directory\n",
    "gmrsDir = f'{repoDir}/examples/records'\n",
    "\n",
    "### Define Output Directory\n",
    "outDir = f'{repoDir}/examples/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8942e1e2",
   "metadata": {},
   "source": [
    "# 2. Define the SDOF-to-MDOF Calibration Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fffdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrateModel(nst,gamma,sdofCapArray):\n",
    "        \n",
    "    # Initialise the mode shape\n",
    "    phi_mdof = np.linspace(1/nst, 1, nst)\n",
    "    print('Assumed Mode-Shape:',phi_mdof)\n",
    "    \n",
    "    # Get the masses\n",
    "    mass = 1/sum(phi_mdof)\n",
    "    print('Floor Mass:',mass)\n",
    "    \n",
    "    # Assign the MDOF mass\n",
    "    flm_mdof = [mass]*nst\n",
    "\n",
    "    ### Get the MDOF Capacity Curves Storey-Deformation Relationship\n",
    "    rows, columns = np.shape(sdofCapArray)\n",
    "    stD_mdof = np.zeros([nst,rows])\n",
    "    stF_mdof = np.zeros([nst,rows])\n",
    "    for i in range(nst):\n",
    "        # get the displacement or spectral displacement arrays at each storey\n",
    "        stF_mdof[i,:] = sdofCapArray[:,1].transpose()*gamma*units.g*sum(flm_mdof)\n",
    "        # get the force or spectral acceleration arrays at each storey\n",
    "        stD_mdof[i,:] = sdofCapArray[:,0].transpose()*gamma*phi_mdof[i]\n",
    "        \n",
    "    ### Get the elastic stiffness of each floor\n",
    "    elasticStiffness = []\n",
    "    for i in range(nst):\n",
    "        elasticStiffness.append(stF_mdof[i,0]/stD_mdof[i,0])\n",
    "        print('Elastic Stiffness of',f'{i+1}-th Storey:', elasticStiffness[i])\n",
    "        \n",
    "    ### Estimate the elastic period\n",
    "    elasticPeriod = 2*pi*np.sqrt(sum(flm_mdof)/sum(elasticStiffness))\n",
    "\n",
    "    ### Prepare the SDOF model\n",
    "    flh_sdof = [2.8]*1 # arbitray height \n",
    "    flm_sdof = [1.0]*1 # unit mass (1 tonne)\n",
    "    rows, columns = np.shape(sdofCapArray)\n",
    "    stD_sdof = np.zeros([1,rows])\n",
    "    stF_sdof = np.zeros([1,rows])\n",
    "    for i in range(1):\n",
    "        # get the displacement or spectral displacement arrays at each storey\n",
    "        stF_sdof[i,:] = sdofCapArray[:,1].transpose()*gamma*units.g\n",
    "        # get the force or spectral acceleration arrays at each storey\n",
    "        stD_sdof[i,:] = sdofCapArray[:,0].transpose()*gamma\n",
    "    \n",
    "    ### Compile the SDOF model\n",
    "    modelSDOF = stickModel(1,flh_sdof,flm_sdof,stD_sdof,stF_sdof)    # Build the model\n",
    "    modelSDOF.mdof_initialise()                                      # Initialise the domain\n",
    "    modelSDOF.mdof_nodes()                                           # Construct the nodes\n",
    "    modelSDOF.mdof_fixity()                                          # Set the boundary conditions \n",
    "    modelSDOF.mdof_loads()                                           # Assign the loads\n",
    "    modelSDOF.mdof_material()                                        # Assign the nonlinear storey material\n",
    "    modelSDOF.plot_model()                                           # Visualise the model                               \n",
    "    modelSDOF.do_gravity_analysis()                                  # Do gravity analysis\n",
    "    sdofT = modelSDOF.do_modal_analysis(num_modes = 1)               # Do modal analysis and get period of vibration\n",
    "\n",
    "    ### Run static pushover analyses on SDOF model\n",
    "    ref_disp = 0.01\n",
    "    disp_scale_factor = 100\n",
    "    push_dir = 1\n",
    "    spoSDOF_disps, spoSDOF_rxn= modelSDOF.do_spo_analysis(ref_disp,disp_scale_factor,push_dir)\n",
    "\n",
    "    ### Compile the MDOF\n",
    "    flh_mdof = [2.8]*nst\n",
    "    modelMDOF = stickModel(nst,flh_mdof,flm_mdof,stD_mdof,stF_mdof)  # Build the model\n",
    "    modelMDOF.mdof_initialise()                                      # Initialise the domain\n",
    "    modelMDOF.mdof_nodes()                                           # Construct the nodes\n",
    "    modelMDOF.mdof_fixity()                                          # Set the boundary conditions \n",
    "    modelMDOF.mdof_loads()                                           # Assign the loads\n",
    "    modelMDOF.mdof_material()                                        # Assign the nonlinear storey material\n",
    "    modelMDOF.plot_model()                                           # Visualise the model                               \n",
    "    modelMDOF.do_gravity_analysis()                                  # Do gravity analysis\n",
    "    mdofT = modelMDOF.do_modal_analysis(num_modes = 1)               # Do modal analysis and get period of vibration\n",
    "\n",
    "    ### Run Static Pushover Analyses on MDOF \n",
    "    ref_disp = 0.01\n",
    "    disp_scale_factor = 20\n",
    "    push_dir = 1\n",
    "    spoMDOF_disps, spoMDOF_rxn= modelSDOF.do_spo_analysis(ref_disp,disp_scale_factor,push_dir)\n",
    "    \n",
    "    ### Test 1: Check the periods\n",
    "    print('SDOF Elastic Period from Modal Analysis:', sdofT[0], 's')\n",
    "    print('MDOF Elastic Period from Modal Analysis:', mdofT[0], 's')\n",
    "    error1 = (sdofT[0]-mdofT[0])/mdofT[0]\n",
    "    if error1 < 1e-1:\n",
    "        print('Period check satisfied!')\n",
    "        print('Error 1:', error1*100)\n",
    "    else:\n",
    "        print('Error 1:', error1*100)\n",
    "        raise ValueError('MDOF and SDOF periods do not match!! Revise your input')\n",
    "    \n",
    "    ### Test 2: Equivalent Masses\n",
    "    error2 = (np.dot(flm_mdof,phi_mdof)-1.00)/1.00\n",
    "    if error2 < 1e-1:\n",
    "        print('Equivalent mass equation verified')\n",
    "        print('Error 2:', error2*100)\n",
    "    else:\n",
    "        print('Error 2:', error2*100)\n",
    "        #raise ValueError('Equivalent mass equation not satisfied!! Revise your input')\n",
    "        \n",
    "    ### Test 3: Transformation Equation\n",
    "    error3 = (np.dot(flm_mdof,phi_mdof**2)-1/gamma)/(1/gamma)\n",
    "    if error3 < 1e-1:\n",
    "        print('Transformation factor equation verified')\n",
    "        print('Error 3:', error3*100)\n",
    "    else:\n",
    "        print('Error 3:', error3*100)\n",
    "        #raise ValueError('Transformation factor equation not satisfied!! Revise your input')\n",
    "        \n",
    "    ### Plot the comparison\n",
    "    fig=plt.figure()    \n",
    "    # Plot the individual storeys\n",
    "    for i in range(nst): \n",
    "        storeyD = np.concatenate(([0.0],stD_mdof[i,:]))\n",
    "        storeyF = np.concatenate(([0.0],stF_mdof[i,:]))\n",
    "        plt.plot(storeyD,storeyF,'--',label = f'storey {i}')\n",
    "    \n",
    "    # Plot the backbone of the SDOF system\n",
    "    plt.plot(spoSDOF_disps[:,-1],spoSDOF_rxn,'r--',label='Model - SDOF')\n",
    "    # Plot the calibrated backbone of the MDOF \n",
    "    plt.plot(spoMDOF_disps[:,-1],spoMDOF_rxn,label='Model - MDOF')\n",
    "    plt.grid(visible=True, which='major')\n",
    "    plt.grid(visible=True, which='minor')\n",
    "    plt.xlabel('Spectral Displacement, Sd [m]')\n",
    "    plt.ylabel('Spectral Acceleration, Sa [g]')\n",
    "    plt.title('Comparison of Capacity Curves')\n",
    "    plt.legend()\n",
    "        \n",
    "    return mdofT, flm_mdof, stD_mdof, stF_mdof\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a6e3e",
   "metadata": {},
   "source": [
    "# 3. Prepare the MDOF Model and Run NLTHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the building class info\n",
    "classInfo = pd.read_csv(f'{capCurvesDir}/in_plane_capacity_parameters_table.csv')\n",
    "\n",
    "### Import the building class info\n",
    "nst          = int(currentBuildingClass.split('H')[-1])\n",
    "storeyHeight = classInfo['Storey_height'].loc[classInfo['Building_class']==currentBuildingClass].item()\n",
    "gamma        = classInfo['Participation_factor'].loc[classInfo['Building_class']==currentBuildingClass].item()\n",
    "\n",
    "### Import the equivalent SDOF capacity array \n",
    "sdofCapArray = np.array(pd.read_csv(f'{capCurvesDir}/{currentBuildingClass}.csv', header = None))[1:,:]\n",
    "\n",
    "### Calibrate the model and get the period, masses, and strength-deformation relationships of all storeys\n",
    "T, flm_mdof, stD_mdof, stF_mdof = calibrateModel(nst,gamma, sdofCapArray)\n",
    "\n",
    "### Get the number of stories and different storey heights\n",
    "nst = int(currentBuildingClass.split('H')[-1])\n",
    "flh_mdof = [2.8]*nst  # Storey heights\n",
    "\n",
    "### Fetch ground motion records\n",
    "gmrs = sorted_alphanumeric(os.listdir(f'{gmDir}/gmrs'))   # Sort the ground-motion records alphanumerically\n",
    "\n",
    "### Initialise storage lists\n",
    "mdof_coll_index_list = []               # List for collapse index\n",
    "mdof_peak_disp_list  = []               # List for peak floor displacement (returns all peak values along the building height)\n",
    "mdof_peak_drift_list = []               # List for peak storey drift (returns all peak values along the building height)\n",
    "mdof_peak_accel_list = []               # List for peak floor acceleration (returns all peak values along the building height)\n",
    "mdof_max_peak_drift_list = []           # List for maximum peak storey drift (returns the maximum value) \n",
    "mdof_max_peak_drift_dir_list = []       # List for maximum peak storey drift directions\n",
    "mdof_max_peak_drift_loc_list = []       # List for maximum peak storey drift locations\n",
    "mdof_max_peak_accel_list = []           # List for maximum peak floor acceleration (returns the maximum value)\n",
    "mdof_max_peak_accel_dir_list = []       # List for maximum peak floor acceleration directions \n",
    "mdof_max_peak_accel_loc_list = []       # List for maximum peak floor acceleration locations \n",
    "mdof_pga = []; mdof_sa = []             # List for intensity measures\n",
    "\n",
    "for i in range(len(gmrs)):\n",
    "    \n",
    "    ### Compile the SDOF model\n",
    "    model = stickModel(nst,flh_mdof,flm_mdof,stD_mdof,stF_mdof)            # Build the model\n",
    "    model.mdof_initialise()                                      # Initialise the domain\n",
    "    model.mdof_nodes()                                           # Construct the nodes\n",
    "    model.mdof_fixity()                                          # Set the boundary conditions \n",
    "    model.mdof_loads()                                           # Assign the loads\n",
    "    model.mdof_material()                                        # Assign the nonlinear storey material\n",
    "    if i==0:\n",
    "        model.plot_model()                                       # Visualise the model\n",
    "    else: \n",
    "        pass\n",
    "    model.do_gravity_analysis()                                  # Do gravity analysis\n",
    "    T = model.do_modal_analysis(num_modes = 1)                   # Do modal analysis and get period of vibration\n",
    "\n",
    "    ### Define ground motion objects\n",
    "    fnames = [f'{gmDir}/gmrs/{gmrs[i]}']                                # Ground-motion record names\n",
    "    fdts = f'{gmDir}/dts/dts_{i}.csv'                                   # Ground-motion time-step names \n",
    "    dt_gm = pd.read_csv(fdts)[pd.read_csv(fdts).columns[0]].loc[0]      # Ground-motion time-step\n",
    "    t_max = pd.read_csv(fdts)[pd.read_csv(fdts).columns[0]].iloc[-1]    # Ground-motion duration\n",
    "\n",
    "    ### Get intensity measures\n",
    "    im = intensityMeasure(pd.read_csv(fnames[0]).to_numpy().flatten(),dt_gm) # Initialise the intensityMeasure object\n",
    "    pga.append(im.get_sa(0.0))                                               # Append PGA values \n",
    "    sa.append(im.get_sa(0.3))                                                # Append Sa(0.3s) values\n",
    "    \n",
    "    ### Define analysis params and do NLTHA\n",
    "    dt_ansys = dt_gm                                                         # Set the analysis time-step\n",
    "    sf = units.g                                                             # Set the scaling factor (if records are in g, a scaling factor of 9.81 m/s2 must be used to be consistent with opensees) \n",
    "    collLimit = 10.00                                                        # Set a large number for numerical collapse\n",
    "    control_nodes, coll_index, peak_drift, peak_accel, max_peak_drift, max_peak_drift_dir, max_peak_drift_loc, max_peak_accel, max_peak_accel_dir, max_peak_accel_loc, peak_disp = model.do_nrha_analysis(fnames, dt_gm, sf, t_max, dt_ansys, collLimit, outDir)\n",
    "\n",
    "    #######################            \n",
    "    ### Store the analysis \n",
    "    #######################\n",
    "    mdof_coll_index_list.append(coll_index)\n",
    "    mdof_peak_drift_list.append(peak_drift)\n",
    "    mdof_peak_accel_list.append(peak_accel)\n",
    "    mdof_peak_disp_list.append(peak_disp)\n",
    "    mdof_max_peak_drift_list.append(max_peak_drift)\n",
    "    mdof_max_peak_drift_dir_list.append(max_peak_drift_dir)\n",
    "    mdof_max_peak_drift_loc_list.append(max_peak_drift_loc)\n",
    "    mdof_max_peak_accel_list.append(max_peak_accel)\n",
    "    mdof_max_peak_accel_dir_list.append(max_peak_accel_dir)\n",
    "    mdof_max_peak_accel_loc_list.append(max_peak_accel_loc)\n",
    "    #######################\n",
    "\n",
    "    print('================================================================')\n",
    "    print('============== ANALYSIS COMPLETED: {:d} out {:d} =================='.format(i+1, len(gmrs)))\n",
    "    print('================================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97ced0",
   "metadata": {},
   "source": [
    "# 4. Prepare the SDOF Model and Run NLTHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare the SDOF model\n",
    "nst = 1                   # Single-degree-of-freedom (nst = 1) \n",
    "flh = [storeyHeight]*nst  # Storey height\n",
    "flm = [1.0]*nst           # Storey mass (unit tonne mass for sdof systems)\n",
    "\n",
    "### Get the storey-strength deformation relationship\n",
    "rows, columns = np.shape(sdofCapArray)\n",
    "stD = np.zeros([nst,rows])\n",
    "stF = np.zeros([nst,rows])\n",
    "for i in range(nst):\n",
    "    # get the displacement or spectral displacement arrays at each storey\n",
    "    stF[i,:] = sdofCapArray[:,1].transpose()*gamma*units.g\n",
    "    # get the force or spectral acceleration arrays at each storey\n",
    "    stD[i,:] = sdofCapArray[:,0].transpose()*gamma   \n",
    "\n",
    "### Fetch ground motion records\n",
    "gmrs = sorted_alphanumeric(os.listdir(f'{gmDir}/gmrs'))   # Sort the ground-motion records alphanumerically\n",
    "\n",
    "### Initialise storage lists\n",
    "sdof_coll_index_list = []               # List for collapse index\n",
    "sdof_peak_disp_list  = []               # List for peak floor displacement (returns all peak values along the building height)\n",
    "sdof_peak_drift_list = []               # List for peak storey drift (returns all peak values along the building height)\n",
    "sdof_peak_accel_list = []               # List for peak floor acceleration (returns all peak values along the building height)\n",
    "sdof_max_peak_drift_list = []           # List for maximum peak storey drift (returns the maximum value) \n",
    "sdof_max_peak_drift_dir_list = []       # List for maximum peak storey drift directions\n",
    "sdof_max_peak_drift_loc_list = []       # List for maximum peak storey drift locations\n",
    "sdof_max_peak_accel_list = []           # List for maximum peak floor acceleration (returns the maximum value)\n",
    "sdof_max_peak_accel_dir_list = []       # List for maximum peak floor acceleration directions \n",
    "sdof_max_peak_accel_loc_list = []       # List for maximum peak floor acceleration locations \n",
    "sdof_pga = []; sdof_sa = []             # List for intensity measures\n",
    "\n",
    "for i in range(len(gmrs)):\n",
    "    \n",
    "    ### Compile the SDOF model\n",
    "    model = stickModel(nst,flh,flm,stD,stF)                      # Build the model\n",
    "    model.mdof_initialise()                                      # Initialise the domain\n",
    "    model.mdof_nodes()                                           # Construct the nodes\n",
    "    model.mdof_fixity()                                          # Set the boundary conditions \n",
    "    model.mdof_loads()                                           # Assign the loads\n",
    "    model.mdof_material()                                        # Assign the nonlinear storey material\n",
    "    if i==0:\n",
    "        model.plot_model()                                       # Visualise the model\n",
    "    else: \n",
    "        pass\n",
    "    model.do_gravity_analysis()                                  # Do gravity analysis\n",
    "    T = model.do_modal_analysis(num_modes = 1)                   # Do modal analysis and get period of vibration\n",
    "    \n",
    "    ### Define ground motion objects\n",
    "    fnames = [f'{gmDir}/gmrs/{gmrs[i]}']                                # Ground-motion record names\n",
    "    fdts = f'{gmDir}/dts/dts_{i}.csv'                                   # Ground-motion time-step names \n",
    "    dt_gm = pd.read_csv(fdts)[pd.read_csv(fdts).columns[0]].loc[0]      # Ground-motion time-step\n",
    "    t_max = pd.read_csv(fdts)[pd.read_csv(fdts).columns[0]].iloc[-1]    # Ground-motion duration\n",
    "    \n",
    "    ### Define analysis params and do NLTHA\n",
    "    dt_ansys = dt_gm                                                         # Set the analysis time-step\n",
    "    sf = units.g                                                             # Set the scaling factor (if records are in g, a scaling factor of 9.81 m/s2 must be used to be consistent with opensees) \n",
    "    collLimit = 10.00                                                        # Set a large number for numerical collapse\n",
    "    control_nodes, coll_index, peak_drift, peak_accel, max_peak_drift, max_peak_drift_dir, max_peak_drift_loc, max_peak_accel, max_peak_accel_dir, max_peak_accel_loc, peak_disp = model.do_nrha_analysis(fnames, dt_gm, sf, t_max, dt_ansys, collLimit, outDir)\n",
    "\n",
    "    #######################            \n",
    "    ### Store the analysis \n",
    "    #######################\n",
    "    sdof_coll_index_list.append(coll_index)\n",
    "    sdof_peak_drift_list.append(peak_drift)\n",
    "    sdof_peak_accel_list.append(peak_accel)\n",
    "    sdof_peak_disp_list.append(peak_disp)\n",
    "    sdof_max_peak_drift_list.append(max_peak_drift)\n",
    "    sdof_max_peak_drift_dir_list.append(max_peak_drift_dir)\n",
    "    sdof_max_peak_drift_loc_list.append(max_peak_drift_loc)\n",
    "    sdof_max_peak_accel_list.append(max_peak_accel)\n",
    "    sdof_max_peak_accel_dir_list.append(max_peak_accel_dir)\n",
    "    sdof_max_peak_accel_loc_list.append(max_peak_accel_loc)\n",
    "    #######################\n",
    "\n",
    "    print('================================================================')\n",
    "    print('============== ANALYSIS COMPLETED: {:d} out {:d} =================='.format(i+1, len(gmrs)))\n",
    "    print('================================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6daa8fb",
   "metadata": {},
   "source": [
    "# 5. Postprocess the Cloud Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process the cloud analysis results for PGA and SA(T1)\n",
    "sdof_imvector1, sdof_edpvector1 = cloudAnalysis(pga, sdof_max_peak_drift_list)\n",
    "mdof_imvector1, mdof_edpvector1 = cloudAnalysis(pga, mdof_max_peak_drift_list)\n",
    "\n",
    "sdof_imvector2, sdof_edpvector2 = cloudAnalysis(sa, sdof_max_peak_drift_list)\n",
    "mdof_imvector2, mdof_edpvector2 = cloudAnalysis(sa, mdof_max_peak_drift_list)\n",
    "\n",
    "\n",
    "### Plot the results for Peak Ground Accelerartion\n",
    "# Plot the sdof cloud and regression\n",
    "plt.scatter(sdof_max_peak_drift_list, pga, alpha = 0.5)\n",
    "plt.plot(sdof_edpvector1, sdof_imvector1, linewidth=8)\n",
    "# Plot the mdof cloud and regression\n",
    "plt.scatter(mdof_max_peak_drift_list, pga, alpha = 0.5)\n",
    "plt.plot(mdof_edpvector1, mdof_imvector1, linewidth=8)\n",
    "\n",
    "plt.xlabel(r'Maximum Peak Storey Drift, $\\theta_{max}$ [%]')\n",
    "plt.ylabel(r'Peak Ground Acceleration, PGA [g]')\n",
    "plt.grid(visible=True, which='major')\n",
    "plt.grid(visible=True, which='minor')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim([5e-3, 1e3])\n",
    "plt.show()\n",
    "\n",
    "### Plot the results for Spectral Acceleration at 0.3s\n",
    "# Plot the sdof cloud and regression\n",
    "plt.scatter(sdof_max_peak_drift_list, sa, alpha = 0.5)\n",
    "plt.plot(sdof_edpvector2, sdof_imvector2, linewidth=8)\n",
    "# Plot the mdof cloud and regression\n",
    "plt.scatter(mdof_max_peak_drift_list, sa, alpha = 0.5)\n",
    "plt.plot(mdof_edpvector2, mdof_imvector2, linewidth=8)\n",
    "\n",
    "plt.xlabel(r'Maximum Peak Storey Drift, $\\theta_{max}$ [%]')\n",
    "plt.ylabel(r'Spectral Acceleration, Sa(T=0.3s) [g]')\n",
    "plt.grid(visible=True, which='major')\n",
    "plt.grid(visible=True, which='minor')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim([5e-3, 1e3])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
